#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#


# Kylin server mode, valid value [all, query, job]
kylin.server.mode=all
kylin.metadata.url=kylin_metadata@jdbc,url=jdbc:mysql://{{ DB_HOST }}:{{ DB_PORT }}/kylin,username=root,password={{ DB_PASSWORD }},maxActive=10,maxIdle=10
kylin.env.zookeeper-connect-string={{ ZOOKEEPER_HOST }}
kylin.env.hdfs-working-dir=s3a:/{{ S3_BUCKET_PATH }}/working_dir/
## Build Engine Resource
kylin.engine.spark-conf.spark.eventLog.dir=s3a:/{{ S3_BUCKET_PATH }}/working_dir/spark-history
kylin.engine.spark-conf.spark.history.fs.logDirectory=s3a:/{{ S3_BUCKET_PATH }}/working_dir/spark-history
kylin.engine.spark-conf.spark.master=spark://{{ SPARK_MASTER }}:7077

kylin.cube.cubeplanner.enabled=false
kylin.engine.spark-conf.spark.executor.cores=2
kylin.engine.spark-conf.spark.executor.instances=4
kylin.engine.spark-conf.spark.executor.memory=7GB
kylin.engine.spark-conf.spark.executor.memoryOverhead=1GB

### support prometheus
kylin.engine.spark-conf.spark.ui.prometheus.enabled=true
kylin.engine.spark-conf.spark.executor.processTreeMetrics.enabled=true

## Parquet Column Index
kylin.engine.spark-conf.spark.hadoop.parquet.page.size=1048576
kylin.engine.spark-conf.spark.hadoop.parquet.page.row.count.limit=100000
kylin.engine.spark-conf.spark.hadoop.parquet.block.size=268435456
kylin.engine.spark-conf.spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem

## Query Engine Resource
kylin.query.spark-conf.spark.master=spark://{{ SPARK_MASTER }}:7077
kylin.query.spark-conf.spark.cores.max=4
kylin.query.spark-conf.spark.driver.cores=1
kylin.query.spark-conf.spark.driver.memory=8GB
kylin.query.spark-conf.spark.driver.memoryOverhead=1G
kylin.query.spark-conf.spark.executor.instances=2
kylin.query.spark-conf.spark.executor.cores=2
kylin.query.spark-conf.spark.executor.memory=7G
kylin.query.spark-conf.spark.executor.memoryOverhead=1G
kylin.query.spark-conf.spark.sql.parquet.filterPushdown=false
kylin.query.spark-conf.spark.hadoop.parquet.filter.columnindex.enabled=true

### support prometheus
kylin.query.spark-conf.spark.ui.prometheus.enabled=true
kylin.query.spark-conf.spark.executor.processTreeMetrics.enabled=true

## Disable canary
kylin.canary.sparder-context-canary-enabled=false
## Query Cache
kylin.query.cache-enabled=true

### Prepare for cluster mode
kylin.job.scheduler.default=100
kylin.server.self-discovery-enabled=true