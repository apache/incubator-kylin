# Generated by Apache Ambari. Thu Mar 19 15:30:10 2020

spark.driver.extraLibraryPath=/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64 -verbose:class
spark.eventLog.dir=hdfs:///spark2-history/
spark.eventLog.enabled=true
spark.executor.extraJavaOptions=-XX:+UseNUMA -Dhdp.version=current
spark.executor.extraLibraryPath=/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.history.fs.cleaner.enabled=true
spark.history.fs.cleaner.interval=7d
spark.history.fs.cleaner.maxAge=90d
spark.history.fs.logDirectory=hdfs:///spark2-history/
spark.history.kerberos.keytab=none
spark.history.kerberos.principal=none
spark.history.provider=org.apache.spark.deploy.history.FsHistoryProvider
spark.history.ui.port=18081
spark.io.compression.lz4.blockSize=128kb
spark.master=yarn
spark.shuffle.service.enabled=false
spark.shuffle.file.buffer=1m
spark.shuffle.io.backLog=8192
spark.shuffle.io.serverThreads=128
spark.shuffle.unsafe.file.output.buffer=5m
spark.sql.autoBroadcastJoinThreshold=26214400
spark.sql.hive.convertMetastoreOrc=true
spark.sql.hive.metastore.jars=/usr/hdp/current/spark2-client/standalone-metastore/*
spark.sql.hive.metastore.version=3.0
spark.sql.orc.filterPushdown=true
spark.sql.orc.impl=native
spark.sql.statistics.fallBackToHdfs=true
spark.sql.warehouse.dir=/apps/spark/warehouse
spark.unsafe.sorter.spill.reader.buffer.size=1m
spark.yarn.historyServer.address=sandbox-hdp.hortonworks.com:18081
spark.yarn.queue=default
# add -verbose:class if any class load issue happened
# -Dhdp.version=current
spark.driver.extraJavaOptions=-Dlog4j.debug -Dhdp.version=current
# -Dlog4j.configuration=file:/{PROJECT-DIR}/examples/test_case_data/sandbox/log4j-driver.properties
spark.yarn.am.extraJavaOptions=-Dhdp.version=current